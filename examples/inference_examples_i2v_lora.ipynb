{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135f0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from kandinsky import get_I2V_pipeline\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99a497",
   "metadata": {},
   "source": [
    "### Load pipe \n",
    "first, ensure that you have downloaded the models using `download_models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5198a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d8d4d53d3045b7917ef62ab4bda496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Magcache\n",
      "load dit on cuda:1\n"
     ]
    }
   ],
   "source": [
    "pipe = get_I2V_pipeline(\n",
    "    device_map={\"dit\": \"cuda:0\", \"vae\": \"cuda:0\", \"text_embedder\": \"cuda:0\"},\n",
    "\tconf_path=\"./configs/k5_lite_i2v_5s_sft_sd.yaml\", magcache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f269979",
   "metadata": {},
   "source": [
    "#### Load LoRa checkpoints from HF\n",
    "\n",
    "Available LoRas for Lite model:\n",
    "\n",
    "    `Arc-right`\n",
    "\n",
    "    `Arc-left`\n",
    "\n",
    "    `Microwave-right`\n",
    "\n",
    "    `Microwave-left`\n",
    "\n",
    "    `Dolly-in`\n",
    "\n",
    "    `Dolly-out`\n",
    "\n",
    "    `Truck-right`\n",
    "\n",
    "    `Trcuk-left`\n",
    "\n",
    "Available LoRas for Pro model:\n",
    "\n",
    "    `Arc-right`\n",
    "\n",
    "    `Arc-left`\n",
    "\n",
    "    `Microwave-right`\n",
    "\n",
    "    `Microwave-left`\n",
    "\n",
    "Note: For optimal performance, select an appropriate LoRa for the t2v or i2v modality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71ce030",
   "metadata": {},
   "source": [
    "##### Download the adapter from HF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e19e34de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b8c5ec5ef4f52a509d938a27912dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cache_dir = './weights'\n",
    "lora_name = 'Microwave-right'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-I2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e988366",
   "metadata": {},
   "source": [
    "Load the adapter into the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0dd4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e6fce3",
   "metadata": {},
   "source": [
    "Note: The trigger words we use are stored in the LoRA safetensors metadata. They are automatically concatenated with prompts during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80df1e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Microwave-right': 'M1CR0W4V3 r0t4tION, 360-degree rotation. '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.peft_triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1b081",
   "metadata": {},
   "source": [
    "Generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e2a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:20<00:00,  2.80s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/i2v_lite_Microwave-right.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = './outputs/loras/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image = \"assets/test_lora.png\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50dc504",
   "metadata": {},
   "source": [
    "Download another adapter and switch to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e074490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e855ab13bb44663ab0e0f57873bb69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_name = 'Microwave-left'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-I2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")\n",
    "\n",
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bf5af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:41<00:00,  2.02s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/i2v_lite_Microwave-left.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_lora.png\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19752f7d",
   "metadata": {},
   "source": [
    "Switch to the previous loaded LoRa adapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7116db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_lora_name = 'Microwave-right'\n",
    "pipe.set_adapter(prev_lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b373622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:41<00:00,  2.02s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/i2v_lite_Microwave-right_v2.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_lora.png\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v2.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8538c3",
   "metadata": {},
   "source": [
    "Disable all adapters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb9f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.disable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baaf023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:37<00:00,  1.95s/it]\n",
      "/home/user/conda/envs/kandinsky-cuda12.8/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/i2v_lite_default.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_lora.png\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_default.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_default.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df629af",
   "metadata": {},
   "source": [
    "Set already loaded adapter again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee69802",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_adapter(prev_lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9df2178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./outputs/loras/i2v_lite_Microwave-right_v3.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pipe(\n",
    "    \"A bear wearing an ushanka hat and holding a balalaika in a snowy forest is dancing.\",\n",
    "    image=\"assets/test_lora.png\",\n",
    "    time_length=5,\n",
    "    num_steps=50,\n",
    "    save_path=os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v3.mp4'),\n",
    "    seed=12345,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'i2v_lite_{prev_lora_name}_v3.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53761aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kandinsky-cuda12.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
